{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Seq2Seq -model\n",
    "Training summary model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:05:14.464341Z",
     "iopub.status.busy": "2025-03-04T14:05:14.464016Z",
     "iopub.status.idle": "2025-03-04T14:05:14.468508Z",
     "shell.execute_reply": "2025-03-04T14:05:14.467781Z",
     "shell.execute_reply.started": "2025-03-04T14:05:14.464305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pretrained Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:05:14.470348Z",
     "iopub.status.busy": "2025-03-04T14:05:14.470124Z",
     "iopub.status.idle": "2025-03-04T14:05:15.459060Z",
     "shell.execute_reply": "2025-03-04T14:05:15.458301Z",
     "shell.execute_reply.started": "2025-03-04T14:05:14.470328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on device: cuda\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "print(f\"Model on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing existing summarization dataset ([CNN / Daily Mail dataset](https://paperswithcode.com/dataset/cnn-daily-mail-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:05:15.460263Z",
     "iopub.status.busy": "2025-03-04T14:05:15.460051Z",
     "iopub.status.idle": "2025-03-04T14:05:18.221495Z",
     "shell.execute_reply": "2025-03-04T14:05:18.220881Z",
     "shell.execute_reply.started": "2025-03-04T14:05:15.460244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summarization_dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a subset of the dataset for faster compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:05:18.222710Z",
     "iopub.status.busy": "2025-03-04T14:05:18.222399Z",
     "iopub.status.idle": "2025-03-04T14:05:18.233461Z",
     "shell.execute_reply": "2025-03-04T14:05:18.232812Z",
     "shell.execute_reply.started": "2025-03-04T14:05:18.222686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 8000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_size, val_size, test_size = 8000, 1000, 1000\n",
    "summarization_subset = DatasetDict({\n",
    "    \"train\": summarization_dataset[\"train\"].select(range(train_size)),\n",
    "    \"validation\": summarization_dataset[\"validation\"].select(range(val_size)),\n",
    "    \"test\": summarization_dataset[\"test\"].select(range(test_size))\n",
    "})\n",
    "\n",
    "print(summarization_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create methods for preprocessing the the summary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:05:18.234460Z",
     "iopub.status.busy": "2025-03-04T14:05:18.234266Z",
     "iopub.status.idle": "2025-03-04T14:05:18.246806Z",
     "shell.execute_reply": "2025-03-04T14:05:18.245968Z",
     "shell.execute_reply.started": "2025-03-04T14:05:18.234443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"Prepare dataset input with cleaned text.\"\"\"\n",
    "    inputs = [f\"Summarize: {article}\" for article in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(examples[\"highlights\"], max_length=150, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data in similar way as the Gutenberg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:05:18.247932Z",
     "iopub.status.busy": "2025-03-04T14:05:18.247682Z",
     "iopub.status.idle": "2025-03-04T14:05:18.310259Z",
     "shell.execute_reply": "2025-03-04T14:05:18.309591Z",
     "shell.execute_reply.started": "2025-03-04T14:05:18.247907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_set = summarization_subset[\"train\"].map(preprocess_function, batched=True)\n",
    "val_set = summarization_subset[\"validation\"].map(preprocess_function, batched=True)\n",
    "test_set = summarization_subset[\"test\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:05:18.796707Z",
     "iopub.status.busy": "2025-03-04T14:05:18.796451Z",
     "iopub.status.idle": "2025-03-04T14:05:18.840127Z",
     "shell.execute_reply": "2025-03-04T14:05:18.839411Z",
     "shell.execute_reply.started": "2025-03-04T14:05:18.796685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "<ipython-input-49-8b7f947fbb69>:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./summarizer_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    load_best_model_at_end=True,\n",
    "    eval_accumulation_steps=32, \n",
    "    fp16=True,\n",
    "    dataloader_num_workers=4,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:05:18.841258Z",
     "iopub.status.busy": "2025-03-04T14:05:18.841050Z",
     "iopub.status.idle": "2025-03-04T14:23:54.628868Z",
     "shell.execute_reply": "2025-03-04T14:23:54.628068Z",
     "shell.execute_reply.started": "2025-03-04T14:05:18.841239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 18:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.772301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.898200</td>\n",
       "      <td>0.733350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.898200</td>\n",
       "      <td>0.729631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.948800</td>\n",
       "      <td>0.728507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.948800</td>\n",
       "      <td>0.728516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=1.3267453369140625, metrics={'train_runtime': 1115.1685, 'train_samples_per_second': 35.869, 'train_steps_per_second': 1.121, 'total_flos': 5413672058880000.0, 'train_loss': 1.3267453369140625, 'epoch': 5.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:23:54.630182Z",
     "iopub.status.busy": "2025-03-04T14:23:54.629851Z",
     "iopub.status.idle": "2025-03-04T14:24:04.184860Z",
     "shell.execute_reply": "2025-03-04T14:24:04.184042Z",
     "shell.execute_reply.started": "2025-03-04T14:23:54.630151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7281055450439453, 'eval_runtime': 9.5439, 'eval_samples_per_second': 104.779, 'eval_steps_per_second': 6.601, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(test_set)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging to HuggingFace via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:26:31.461910Z",
     "iopub.status.busy": "2025-03-04T14:26:31.461568Z",
     "iopub.status.idle": "2025-03-04T14:26:31.877008Z",
     "shell.execute_reply": "2025-03-04T14:26:31.876300Z",
     "shell.execute_reply.started": "2025-03-04T14:26:31.461883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "from huggingface_hub import login\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"Hugging_Face_Token\")\n",
    "login(UserSecretsClient().get_secret(\"Hugging_Face_Token\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model into hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T14:26:34.684478Z",
     "iopub.status.busy": "2025-03-04T14:26:34.684170Z",
     "iopub.status.idle": "2025-03-04T14:26:50.284387Z",
     "shell.execute_reply": "2025-03-04T14:26:50.283608Z",
     "shell.execute_reply.started": "2025-03-04T14:26:34.684456Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ddcf6306154a22a7e8b5b4aa6680a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071b94acec7c440eaaf8d76357f28d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4261c34331624a70b7fb2d9a13296b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Juh6973/t5-small-summarizer-cnn-dailymail/commit/6943841634443573a40c6c72c15d4db46ee2ee30', commit_message='Upload tokenizer', commit_description='', oid='6943841634443573a40c6c72c15d4db46ee2ee30', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Juh6973/t5-small-summarizer-cnn-dailymail', endpoint='https://huggingface.co', repo_type='model', repo_id='Juh6973/t5-small-summarizer-cnn-dailymail'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = \"Juh6973/t5-small-summarizer-cnn-dailymail\"\n",
    "model.push_to_hub(repo)\n",
    "tokenizer.push_to_hub(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
