{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dense Passage Retrieval\n","metadata":{}},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"!pip install faiss-gpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:14:25.989890Z","iopub.execute_input":"2025-03-05T07:14:25.990092Z","iopub.status.idle":"2025-03-05T07:14:32.927908Z","shell.execute_reply.started":"2025-03-05T07:14:25.990072Z","shell.execute_reply":"2025-03-05T07:14:32.927079Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport requests\nimport nltk\nimport numpy as np\nimport faiss\nimport torch\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# nltk.download(\"punkt\")\n# nltk.download(\"stopwords\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:19:36.990273Z","iopub.execute_input":"2025-03-05T07:19:36.990663Z","iopub.status.idle":"2025-03-05T07:19:36.995417Z","shell.execute_reply.started":"2025-03-05T07:19:36.990635Z","shell.execute_reply":"2025-03-05T07:19:36.994418Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Data\nRead the data from URLs:","metadata":{}},{"cell_type":"code","source":"ebook_urls = [\n    \"https://www.gutenberg.org/cache/epub/56640/pg56640.txt\",\n    \"https://www.gutenberg.org/cache/epub/67813/pg67813.txt\",\n    \"https://www.gutenberg.org/cache/epub/20772/pg20772.txt\",\n    \"https://www.gutenberg.org/cache/epub/40190/pg40190.txt\",\n    \"https://www.gutenberg.org/cache/epub/4924/pg4924.txt\",\n    \"https://www.gutenberg.org/cache/epub/4525/pg4525.txt\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:16:00.032116Z","iopub.execute_input":"2025-03-05T07:16:00.032471Z","iopub.status.idle":"2025-03-05T07:16:00.036271Z","shell.execute_reply.started":"2025-03-05T07:16:00.032443Z","shell.execute_reply":"2025-03-05T07:16:00.035170Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Read the data into dataframe","metadata":{}},{"cell_type":"code","source":"text = \" \". join([requests.get(url).text for url in ebook_urls])\nprint(f\"Raw text length: {len(text)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:16:00.987345Z","iopub.execute_input":"2025-03-05T07:16:00.987647Z","iopub.status.idle":"2025-03-05T07:16:04.903431Z","shell.execute_reply.started":"2025-03-05T07:16:00.987623Z","shell.execute_reply":"2025-03-05T07:16:04.902682Z"}},"outputs":[{"name":"stdout","text":"Raw text length: 3131512\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Convert all text to lower case","metadata":{}},{"cell_type":"code","source":"text = text.lower()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:16:04.904394Z","iopub.execute_input":"2025-03-05T07:16:04.904711Z","iopub.status.idle":"2025-03-05T07:16:04.930652Z","shell.execute_reply.started":"2025-03-05T07:16:04.904677Z","shell.execute_reply":"2025-03-05T07:16:04.929656Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Remove all non-alphanumeric characters except spaces and punctuations","metadata":{}},{"cell_type":"code","source":"text = re.sub(r\"[^a-zA-Z0-9\\s,\\.!?]\", \" \", text)\ntext = re.sub(r\"\\s+\", \" \", text).strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:16:04.931968Z","iopub.execute_input":"2025-03-05T07:16:04.932266Z","iopub.status.idle":"2025-03-05T07:16:05.168370Z","shell.execute_reply.started":"2025-03-05T07:16:04.932234Z","shell.execute_reply":"2025-03-05T07:16:05.167417Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Create a method for removing stopwords and applying stemming","metadata":{}},{"cell_type":"code","source":"def preprocess_for_embeddings(input_text):\n    \"\"\"\n    removes stopwords, and stems.\n    Returns a preprocessed string that is suitable for embedding.\n    \"\"\"\n    stemmer = PorterStemmer()\n    sw = set(stopwords.words(\"english\"))\n    tokens = word_tokenize(input_text)\n    \n    preproc_tokens = [stemmer.stem(t) for t in tokens if t not in sw]\n    preproc_text = \" \".join(preproc_tokens)\n    \n    return preproc_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:16:06.237537Z","iopub.execute_input":"2025-03-05T07:16:06.237867Z","iopub.status.idle":"2025-03-05T07:16:06.242456Z","shell.execute_reply.started":"2025-03-05T07:16:06.237838Z","shell.execute_reply":"2025-03-05T07:16:06.241633Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Chunking\nChunk text into passages. DPR works best with short passages (~100 words each).","metadata":{}},{"cell_type":"code","source":"def chunk_text(text, chunk_size=100):\n    words = text.split()\n    chunks = [\" \".join(words[i : i + chunk_size]) for i in range(0, len(words), chunk_size)]\n    return chunks\n\npassages = chunk_text(text, chunk_size=100)\nprint(f\"Total passages created: {len(passages)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:16:08.919582Z","iopub.execute_input":"2025-03-05T07:16:08.919886Z","iopub.status.idle":"2025-03-05T07:16:08.992300Z","shell.execute_reply.started":"2025-03-05T07:16:08.919861Z","shell.execute_reply":"2025-03-05T07:16:08.991385Z"}},"outputs":[{"name":"stdout","text":"Total passages created: 5289\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## DPR encoding\nLoad DPR Context Encoder\n","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ncontext_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(device)\ncontext_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\nprint(f\"Model on device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:16:38.697438Z","iopub.execute_input":"2025-03-05T07:16:38.697731Z","iopub.status.idle":"2025-03-05T07:16:44.667399Z","shell.execute_reply.started":"2025-03-05T07:16:38.697709Z","shell.execute_reply":"2025-03-05T07:16:44.666432Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/492 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ced20954c514a84a4eb8bddaacc092d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23dbff006cef4c73ba8278847bfbd423"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a064ea92b58b416e96a609e2f6260b0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4579f1564c1f477cb0ad39c7cdb65c75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2e8325786844b2c9881556824bd6506"}},"metadata":{}},{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \nThe class this function is called from is 'DPRContextEncoderTokenizer'.\n","output_type":"stream"},{"name":"stdout","text":"Model on device: cuda\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Tokenize passages","metadata":{}},{"cell_type":"code","source":"context_inputs = context_tokenizer(passages, padding=True, truncation=True, return_tensors=\"pt\").to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:16:49.294283Z","iopub.execute_input":"2025-03-05T07:16:49.294696Z","iopub.status.idle":"2025-03-05T07:17:01.345381Z","shell.execute_reply.started":"2025-03-05T07:16:49.294662Z","shell.execute_reply":"2025-03-05T07:17:01.344397Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Create dataloader","metadata":{}},{"cell_type":"code","source":"batch_size = 16\ndataset = TensorDataset(context_inputs[\"input_ids\"], context_inputs[\"attention_mask\"])\ndataloader = DataLoader(dataset, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:20:42.981838Z","iopub.execute_input":"2025-03-05T07:20:42.982181Z","iopub.status.idle":"2025-03-05T07:20:42.986742Z","shell.execute_reply.started":"2025-03-05T07:20:42.982155Z","shell.execute_reply":"2025-03-05T07:20:42.985783Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"Compute embeddings","metadata":{}},{"cell_type":"code","source":"context_embeddings_list = []\nwith torch.no_grad():\n    for idx, batch in enumerate(dataloader):\n        idx += 1\n        if idx % 25 == 0: print(f\"({idx}/{len(dataloader)}) embedded\")\n        \n        input_ids, attention_mask = batch\n        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n        batch_embeddings = context_encoder(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n        context_embeddings_list.append(batch_embeddings.cpu())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:24:31.039298Z","iopub.execute_input":"2025-03-05T07:24:31.039646Z","iopub.status.idle":"2025-03-05T07:25:15.255829Z","shell.execute_reply.started":"2025-03-05T07:24:31.039621Z","shell.execute_reply":"2025-03-05T07:25:15.254796Z"}},"outputs":[{"name":"stdout","text":"(25/331) embedded\n(50/331) embedded\n(75/331) embedded\n(100/331) embedded\n(125/331) embedded\n(150/331) embedded\n(175/331) embedded\n(200/331) embedded\n(225/331) embedded\n(250/331) embedded\n(275/331) embedded\n(300/331) embedded\n(325/331) embedded\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Convert embeddings to NumPy for FAISS","metadata":{}},{"cell_type":"code","source":"context_embeddings_np = torch.cat(context_embeddings_list, dim=0).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:25:19.274349Z","iopub.execute_input":"2025-03-05T07:25:19.274690Z","iopub.status.idle":"2025-03-05T07:25:19.295413Z","shell.execute_reply.started":"2025-03-05T07:25:19.274662Z","shell.execute_reply":"2025-03-05T07:25:19.294541Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Saving the embeddings for Fast Retrieval\nSave embeddings and passages","metadata":{}},{"cell_type":"code","source":"np.save(\"embeddings.npy\", context_embeddings_np)\nwith open(\"passages.txt\", \"w\") as f:\n    for passage in passages: f.write(passage + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:27:26.224210Z","iopub.execute_input":"2025-03-05T07:27:26.224600Z","iopub.status.idle":"2025-03-05T07:27:26.246849Z","shell.execute_reply.started":"2025-03-05T07:27:26.224568Z","shell.execute_reply":"2025-03-05T07:27:26.246161Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"Store embeddings in FAISS","metadata":{}},{"cell_type":"code","source":"index = faiss.IndexFlatIP(context_embeddings_np.shape[1])\nindex.add(context_embeddings_np)\nfaiss.write_index(index, \"faiss_index.bin\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:30:29.805019Z","iopub.execute_input":"2025-03-05T07:30:29.805373Z","iopub.status.idle":"2025-03-05T07:30:29.845268Z","shell.execute_reply.started":"2025-03-05T07:30:29.805348Z","shell.execute_reply":"2025-03-05T07:30:29.844360Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Load Precomputed Embeddings & Search Faster\nLoad the precomputed embeddings and FAISS index.","metadata":{}},{"cell_type":"code","source":"context_embeddings_np = np.load(\"embeddings.npy\")\nwith open(\"passages.txt\", \"r\") as f: passages = [line.strip() for line in f]\nindex = faiss.read_index(\"faiss_index.bin\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:32:10.322508Z","iopub.execute_input":"2025-03-05T07:32:10.322836Z","iopub.status.idle":"2025-03-05T07:32:10.348386Z","shell.execute_reply.started":"2025-03-05T07:32:10.322812Z","shell.execute_reply":"2025-03-05T07:32:10.347409Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Encode Query and Retrieve Relevant Passages\nLoad DPR Question Encoder","metadata":{}},{"cell_type":"code","source":"question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\nquestion_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:33:10.387418Z","iopub.execute_input":"2025-03-05T07:33:10.387737Z","iopub.status.idle":"2025-03-05T07:33:15.674497Z","shell.execute_reply.started":"2025-03-05T07:33:10.387713Z","shell.execute_reply":"2025-03-05T07:33:15.673652Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/493 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad95560aef24c40a0196891e211caa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bf0c24dcbed46b2b73473009edcc838"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"100dd234d54f46fdae7322a2ef8c89ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33f2edc2cf484e24a9ead053e67f569e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fad4a2e7f29422786e5e5aa73173e26"}},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"A method for passage retrieval","metadata":{}},{"cell_type":"code","source":"def retrieve_best_passage(query, top_k=3):\n    query_inputs = question_tokenizer(query, return_tensors=\"pt\")\n    with torch.no_grad(): query_embedding = question_encoder(**query_inputs).pooler_output.cpu().numpy()\n\n    # Search in FAISS index\n    D, I = index.search(query_embedding, k=top_k)\n    results = [(passages[I[0][i]], D[0][i]) for i in range(top_k)]\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:34:48.509172Z","iopub.execute_input":"2025-03-05T07:34:48.509519Z","iopub.status.idle":"2025-03-05T07:34:48.513910Z","shell.execute_reply.started":"2025-03-05T07:34:48.509488Z","shell.execute_reply":"2025-03-05T07:34:48.513128Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"Example query","metadata":{}},{"cell_type":"code","source":"query = \"What fertilizer usually contains?\"\ntop_matches = retrieve_best_passage(query)\n\nfor i, (text, score) in enumerate(top_matches): print(f\"Match {i+1} (Score: {score:.4f}):\\n{text}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T07:36:14.496723Z","iopub.execute_input":"2025-03-05T07:36:14.497065Z","iopub.status.idle":"2025-03-05T07:36:14.555765Z","shell.execute_reply.started":"2025-03-05T07:36:14.497036Z","shell.execute_reply":"2025-03-05T07:36:14.554871Z"}},"outputs":[{"name":"stdout","text":"Match 1 (Score: 79.1917):\na thin layer or fold of animal or vegetable matter. mildew a cobwebby growth of fungi on diseased or decaying things. mold see mildew. mulch a covering of straw, leaves, or like substances over the roots of plants to protect them from heat, drought, etc., and to preserve moisture. nectar a sweetish substance in blossoms of flowers from which bees make honey. nitrate a readily usable form of nitrogen. the most common nitrate is saltpeter. nitrogen a chemical element, one of the most important and most expensive plant foods. it exists in fertilizers, in ammonia, in nitrates, and in organic\nMatch 2 (Score: 78.4641):\nor other legumes there is seldom need of using nitrogen in the fertilizer the tubercles on the pea or clover roots will furnish that. hence, as a rule, only potash and phosphoric acid will have to be purchased as plant food. the farmer is assisted always by a study of his crop and by a knowledge of how it grows. if he find the straw inferior and short, it means that the soil is deficient in nitrogen but on the other hand, if the straw be luxuriant and the heads small and poorly filled, he may be sure that his\nMatch 3 (Score: 76.8814):\nchemical name given to many sour substances. vinegar and lemon juice owe their sour taste to the acid in them. adult a person, animal, or plant grown to full size and strength. ammonia ammonium a compound of nitrogen readily usable as a plant food. it is one of the products of decay. annual a plant that bears seed during the first year of its existence and then dies. anther the part of a stamen that bears the pollen. atmospheric nitrogen nitrogen in the air. great quantities of this valuable plant food are in the air but, strange to say, most\n","output_type":"stream"}],"execution_count":26}]}